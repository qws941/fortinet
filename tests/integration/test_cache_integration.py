#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ìºì‹œ ê³„ì¸µ ì¼ê´€ì„± í†µí•© í…ŒìŠ¤íŠ¸ - Rust ìŠ¤íƒ€ì¼ ì¸ë¼ì¸ í…ŒìŠ¤íŠ¸
Redis â†” Memory â†” File ì‹œìŠ¤í…œ ê°„ ìºì‹œ ë™ê¸°í™”, ìŠ¹ê²©/ê°•ë“±, ì¥ì•  ë³µêµ¬ í†µí•© í…ŒìŠ¤íŠ¸
"""

import json
import os
import pickle
import sys
import tempfile
import threading
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
from unittest.mock import MagicMock, patch

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.utils.integration_test_framework import test_framework
from src.utils.redis_cache import RedisCache
from src.utils.unified_cache_manager import UnifiedCacheManager, get_cache_manager


class MockRedisClient:
    """Redis í´ë¼ì´ì–¸íŠ¸ ëª¨í‚¹ì„ ìœ„í•œ í´ë˜ìŠ¤"""

    def __init__(self, fail_mode: bool = False):
        self.data = {}
        self.fail_mode = fail_mode
        self.operation_count = 0
        self.connection_active = not fail_mode

    def get(self, key: str) -> Optional[bytes]:
        """Redis GET ì‹œë®¬ë ˆì´ì…˜"""
        self.operation_count += 1
        if self.fail_mode:
            raise ConnectionError("Redis connection failed")

        value = self.data.get(key)
        return value.encode() if value else None

    def set(self, key: str, value: Union[str, bytes], ex: Optional[int] = None) -> bool:
        """Redis SET ì‹œë®¬ë ˆì´ì…˜"""
        self.operation_count += 1
        if self.fail_mode:
            raise ConnectionError("Redis connection failed")

        if isinstance(value, bytes):
            value = value.decode()
        self.data[key] = value
        return True

    def delete(self, key: str) -> int:
        """Redis DELETE ì‹œë®¬ë ˆì´ì…˜"""
        self.operation_count += 1
        if self.fail_mode:
            raise ConnectionError("Redis connection failed")

        if key in self.data:
            del self.data[key]
            return 1
        return 0

    def exists(self, key: str) -> int:
        """Redis EXISTS ì‹œë®¬ë ˆì´ì…˜"""
        self.operation_count += 1
        if self.fail_mode:
            raise ConnectionError("Redis connection failed")

        return 1 if key in self.data else 0

    def flushall(self) -> bool:
        """Redis FLUSHALL ì‹œë®¬ë ˆì´ì…˜"""
        self.operation_count += 1
        if self.fail_mode:
            raise ConnectionError("Redis connection failed")

        self.data.clear()
        return True

    def ping(self) -> bool:
        """Redis PING ì‹œë®¬ë ˆì´ì…˜"""
        self.operation_count += 1
        if self.fail_mode:
            raise ConnectionError("Redis connection failed")
        return True

    def simulate_failure(self):
        """ì—°ê²° ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜"""
        self.fail_mode = True
        self.connection_active = False

    def simulate_recovery(self):
        """ì—°ê²° ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜"""
        self.fail_mode = False
        self.connection_active = True


class CacheIntegrationTester:
    """ìºì‹œ í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""

    def __init__(self):
        self.mock_redis = MockRedisClient()
        self.temp_dir = tempfile.mkdtemp()
        self.cache_operations = []

    def create_test_cache_manager(self, redis_enabled: bool = True) -> UnifiedCacheManager:
        """í…ŒìŠ¤íŠ¸ìš© ìºì‹œ ë§¤ë‹ˆì € ìƒì„±"""
        # ì„ì‹œ ë””ë ‰í† ë¦¬ì—ì„œ ìºì‹œ ë§¤ë‹ˆì € ìƒì„±
        cache_manager = UnifiedCacheManager()

        if redis_enabled:
            # Mock Redis í´ë¼ì´ì–¸íŠ¸ ì£¼ì…
            cache_manager.redis_cache.client = self.mock_redis
            cache_manager.redis_cache.enabled = True
        else:
            cache_manager.redis_cache.enabled = False

        return cache_manager

    def generate_test_data(self, size: int = 100) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±"""
        return {
            f"test_key_{i}": {
                "id": i,
                "name": f"test_item_{i}",
                "timestamp": time.time(),
                "data": f"test_data_{i}" * 10,  # ì¼ì • í¬ê¸°ì˜ ë°ì´í„°
            }
            for i in range(size)
        }

    def log_cache_operation(self, operation: str, key: str, backend: str, result: Any):
        """ìºì‹œ ì‘ì—… ë¡œê¹…"""
        self.cache_operations.append(
            {
                "operation": operation,
                "key": key,
                "backend": backend,
                "result": result,
                "timestamp": time.time(),
            }
        )


# ìºì‹œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
cache_tester = CacheIntegrationTester()


@test_framework.test("unified_cache_manager_initialization")
def test_cache_manager_init():
    """í†µí•© ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™” ê²€ì¦"""

    cache_manager = cache_tester.create_test_cache_manager()

    # ê¸°ë³¸ ì†ì„± í™•ì¸
    test_framework.assert_ok(hasattr(cache_manager, "backends"), "Cache manager should have backends")
    test_framework.assert_ok(hasattr(cache_manager, "redis_cache"), "Cache manager should have Redis cache")
    test_framework.assert_ok(hasattr(cache_manager, "memory_cache"), "Cache manager should have memory cache")

    # ë°±ì—”ë“œ ìˆœì„œ í™•ì¸ (Redis -> Memory -> File)
    backends = getattr(cache_manager, "backends", [])
    test_framework.assert_ok(len(backends) >= 2, "Should have at least memory and file backends")

    # ê° ë°±ì—”ë“œ ê¸°ëŠ¥ í™•ì¸
    test_cache_key = "test_init_key"
    test_cache_value = {"init_test": True, "timestamp": time.time()}

    # Memory cache í…ŒìŠ¤íŠ¸
    memory_set_result = cache_manager.memory_cache.set(test_cache_key, test_cache_value)
    test_framework.assert_ok(memory_set_result, "Memory cache set should succeed")

    memory_get_result = cache_manager.memory_cache.get(test_cache_key)
    test_framework.assert_eq(
        memory_get_result,
        test_cache_value,
        "Memory cache get should return stored value",
    )

    assert True  # Test passed


@test_framework.test("cache_tier_promotion_and_demotion")
def test_cache_tier_operations():
    """ìºì‹œ ê³„ì¸µ ê°„ ìŠ¹ê²© ë° ê°•ë“± ë¡œì§ ê²€ì¦"""

    cache_manager = cache_tester.create_test_cache_manager()
    test_data = cache_tester.generate_test_data(10)

    promotion_demotion_results = []

    for key, value in test_data.items():
        # 1ë‹¨ê³„: Memory cacheì—ë§Œ ì €ì¥
        memory_set = cache_manager.memory_cache.set(key, value, ttl=300)
        cache_tester.log_cache_operation("set", key, "memory", memory_set)

        # 2ë‹¨ê³„: Redisë¡œ ìŠ¹ê²© ì‹œë®¬ë ˆì´ì…˜
        try:
            redis_set = cache_manager.redis_cache.set(key, value, ttl=300)
            cache_tester.log_cache_operation("promote_to_redis", key, "redis", redis_set)
        except Exception as e:
            cache_tester.log_cache_operation("promote_to_redis", key, "redis", f"failed: {e}")
            redis_set = False

        # 3ë‹¨ê³„: í†µí•© ìºì‹œì—ì„œ ì¡°íšŒ (ê³„ì¸µ ìˆœì„œ í™•ì¸)
        unified_get = cache_manager.get(key)
        cache_tester.log_cache_operation("unified_get", key, "unified", unified_get is not None)

        # ê²€ì¦: ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ê²Œ ì €ì¥/ì¡°íšŒë˜ëŠ”ì§€ í™•ì¸
        test_framework.assert_ok(memory_set, f"Memory cache set should succeed for {key}")
        test_framework.assert_ok(unified_get is not None, f"Unified cache get should return data for {key}")

        if unified_get:
            test_framework.assert_eq(unified_get, value, f"Retrieved data should match stored data for {key}")

        promotion_demotion_results.append(
            {
                "key": key,
                "memory_set": memory_set,
                "redis_set": redis_set,
                "unified_get_success": unified_get is not None,
                "data_integrity": unified_get == value if unified_get else False,
            }
        )

    # ì „ì²´ ì‘ì—… ê²°ê³¼ ê²€ì¦
    successful_operations = [r for r in promotion_demotion_results if r["unified_get_success"]]
    test_framework.assert_ok(len(successful_operations) > 0, "At least some cache operations should succeed")

    assert True  # Test passed


@test_framework.test("redis_failure_and_fallback")
def test_redis_failure_fallback():
    """Redis ì¥ì•  ì‹œ í´ë°± ë™ì‘ ê²€ì¦"""

    # Redis í™œì„±í™”ëœ ìºì‹œ ë§¤ë‹ˆì € ìƒì„±
    cache_manager = cache_tester.create_test_cache_manager(redis_enabled=True)

    # ì •ìƒ ìƒíƒœì—ì„œ ë°ì´í„° ì €ì¥
    test_key = "redis_failure_test"
    test_value = {"test": "redis_failure", "timestamp": time.time()}

    # 1ë‹¨ê³„: ì •ìƒ ìƒíƒœì—ì„œ ì €ì¥
    normal_set = cache_manager.set(test_key, test_value, ttl=300)
    normal_get = cache_manager.get(test_key)

    test_framework.assert_ok(normal_set, "Normal cache set should succeed")
    test_framework.assert_eq(normal_get, test_value, "Normal cache get should return stored value")

    # 2ë‹¨ê³„: Redis ì¥ì•  ì‹œë®¬ë ˆì´ì…˜
    cache_tester.mock_redis.simulate_failure()

    # Redis ì¥ì•  ìƒíƒœì—ì„œ ìƒˆë¡œìš´ ë°ì´í„° ì €ì¥ ì‹œë„
    failure_test_key = "redis_failure_new_data"
    failure_test_value = {"test": "failure_fallback", "timestamp": time.time()}

    failure_set = cache_manager.set(failure_test_key, failure_test_value, ttl=300)
    failure_get = cache_manager.get(failure_test_key)

    # Memory cacheë¡œ í´ë°±ë˜ì–´ ë™ì‘í•´ì•¼ í•¨
    test_framework.assert_ok(
        failure_set,
        "Cache set should succeed even with Redis failure (memory fallback)",
    )
    test_framework.assert_eq(failure_get, failure_test_value, "Cache get should work with memory fallback")

    # 3ë‹¨ê³„: Redis ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜
    cache_tester.mock_redis.simulate_recovery()

    # ë³µêµ¬ í›„ ìƒˆë¡œìš´ ë°ì´í„° ì €ì¥
    recovery_test_key = "redis_recovery_test"
    recovery_test_value = {"test": "recovery", "timestamp": time.time()}

    recovery_set = cache_manager.set(recovery_test_key, recovery_test_value, ttl=300)
    recovery_get = cache_manager.get(recovery_test_key)

    test_framework.assert_ok(recovery_set, "Cache set should succeed after Redis recovery")
    test_framework.assert_eq(recovery_get, recovery_test_value, "Cache get should work after Redis recovery")

    # Test completed successfully
    print(f"âœ… Failure fallback - set: {failure_set}, get: {failure_get == failure_test_value}")
    print(f"âœ… Recovery operation - set: {recovery_set}, get: {recovery_get == recovery_test_value}")
    print("âœ… Redis failure handling test completed")


@test_framework.test("cache_consistency_across_backends")
def test_cache_consistency():
    """ë°±ì—”ë“œ ê°„ ìºì‹œ ì¼ê´€ì„± ê²€ì¦"""

    cache_manager = cache_tester.create_test_cache_manager()

    # ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ ë°ì´í„°
    consistency_tests = [
        {"key": "consistency_test_1", "value": {"data": "test1", "type": "string"}},
        {"key": "consistency_test_2", "value": {"data": 12345, "type": "number"}},
        {"key": "consistency_test_3", "value": {"data": [1, 2, 3], "type": "array"}},
        {
            "key": "consistency_test_4",
            "value": {"data": {"nested": True}, "type": "object"},
        },
    ]

    consistency_results = []

    for test_case in consistency_tests:
        key = test_case["key"]
        value = test_case["value"]

        # 1ë‹¨ê³„: í†µí•© ìºì‹œì— ì €ì¥
        unified_set = cache_manager.set(key, value, ttl=300)

        # 2ë‹¨ê³„: ê° ë°±ì—”ë“œì—ì„œ ì§ì ‘ ì¡°íšŒ
        memory_get = cache_manager.memory_cache.get(key)

        try:
            redis_get = cache_manager.redis_cache.get(key)
        except:
            redis_get = None  # Redis ì‹¤íŒ¨ ì‹œ None

        # 3ë‹¨ê³„: í†µí•© ìºì‹œì—ì„œ ì¡°íšŒ
        unified_get = cache_manager.get(key)

        # ì¼ê´€ì„± ê²€ì¦
        memory_consistent = memory_get == value if memory_get else False
        unified_consistent = unified_get == value if unified_get else False

        consistency_results.append(
            {
                "key": key,
                "value_type": test_case["value"]["type"],
                "unified_set": unified_set,
                "memory_consistent": memory_consistent,
                "redis_available": redis_get is not None,
                "unified_consistent": unified_consistent,
                "overall_consistent": unified_consistent and memory_consistent,
            }
        )

        # ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì— ëŒ€í•œ ê²€ì¦
        test_framework.assert_ok(unified_set, f"Unified cache set should succeed for {key}")
        test_framework.assert_ok(unified_consistent, f"Data should be consistent in unified cache for {key}")

    # ì „ì²´ ì¼ê´€ì„± ê²€ì¦
    all_consistent = all(result["overall_consistent"] for result in consistency_results)
    test_framework.assert_ok(all_consistent, "All cache backends should maintain data consistency")

    assert True  # Test passed


@test_framework.test("concurrent_cache_access")
def test_concurrent_cache_access():
    """ë™ì‹œ ìºì‹œ ì ‘ê·¼ ì²˜ë¦¬ ê²€ì¦"""

    cache_manager = cache_tester.create_test_cache_manager()

    concurrent_results = []
    cache_access_threads = []
    shared_results = []

    def concurrent_cache_worker(worker_id: int, operation_count: int):
        """ë™ì‹œ ìºì‹œ ì ‘ê·¼ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ì›Œì»¤"""
        worker_results = []

        for i in range(operation_count):
            key = f"concurrent_test_{worker_id}_{i}"
            value = {"worker_id": worker_id, "operation": i, "timestamp": time.time()}

            try:
                # ìºì‹œ ì €ì¥
                set_result = cache_manager.set(key, value, ttl=300)

                # ì¦‰ì‹œ ì¡°íšŒ
                get_result = cache_manager.get(key)

                # ê²°ê³¼ ê²€ì¦
                is_consistent = get_result == value if get_result else False

                worker_results.append(
                    {
                        "worker_id": worker_id,
                        "operation": i,
                        "key": key,
                        "set_success": set_result,
                        "get_success": get_result is not None,
                        "data_consistent": is_consistent,
                    }
                )

            except Exception as e:
                worker_results.append(
                    {
                        "worker_id": worker_id,
                        "operation": i,
                        "key": key,
                        "error": str(e),
                        "set_success": False,
                        "get_success": False,
                        "data_consistent": False,
                    }
                )

        shared_results.extend(worker_results)

    # ë™ì‹œ ì›Œì»¤ ìƒì„± ë° ì‹¤í–‰
    num_workers = 5
    operations_per_worker = 10

    for worker_id in range(num_workers):
        thread = threading.Thread(target=concurrent_cache_worker, args=(worker_id, operations_per_worker))
        cache_access_threads.append(thread)

    # ëª¨ë“  ìŠ¤ë ˆë“œ ì‹œì‘
    start_time = time.time()
    for thread in cache_access_threads:
        thread.start()

    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    for thread in cache_access_threads:
        thread.join(timeout=15)  # 15ì´ˆ íƒ€ì„ì•„ì›ƒ

    end_time = time.time()

    # ê²°ê³¼ ë¶„ì„
    total_operations = num_workers * operations_per_worker
    successful_operations = [r for r in shared_results if r["set_success"] and r["get_success"]]
    consistent_operations = [r for r in shared_results if r["data_consistent"]]

    # ê²€ì¦
    test_framework.assert_eq(
        len(shared_results),
        total_operations,
        f"All {total_operations} operations should complete",
    )

    test_framework.assert_ok(
        len(successful_operations) > total_operations * 0.9,
        "At least 90% of operations should succeed",
    )

    test_framework.assert_ok(
        len(consistent_operations) > total_operations * 0.9,
        "At least 90% of operations should maintain data consistency",
    )

    assert True  # Test passed


@test_framework.test("cache_ttl_and_expiration")
def test_cache_ttl_expiration():
    """ìºì‹œ TTL ë° ë§Œë£Œ ì²˜ë¦¬ ê²€ì¦"""

    cache_manager = cache_tester.create_test_cache_manager()

    ttl_tests = [
        {"key": "ttl_test_short", "value": {"data": "short_ttl"}, "ttl": 1},  # 1ì´ˆ
        {"key": "ttl_test_medium", "value": {"data": "medium_ttl"}, "ttl": 5},  # 5ì´ˆ
        {"key": "ttl_test_long", "value": {"data": "long_ttl"}, "ttl": 300},  # 5ë¶„
    ]

    ttl_results = []

    for test_case in ttl_tests:
        key = test_case["key"]
        value = test_case["value"]
        ttl = test_case["ttl"]

        # TTLê³¼ í•¨ê»˜ ë°ì´í„° ì €ì¥
        set_result = cache_manager.set(key, value, ttl=ttl)
        test_framework.assert_ok(set_result, f"Cache set with TTL should succeed for {key}")

        # ì¦‰ì‹œ ì¡°íšŒ (ë§Œë£Œ ì „)
        immediate_get = cache_manager.get(key)
        test_framework.assert_eq(immediate_get, value, f"Immediate get should return stored value for {key}")

        ttl_results.append(
            {
                "key": key,
                "ttl": ttl,
                "set_success": set_result,
                "immediate_get_success": immediate_get == value,
                "test_type": "short" if ttl <= 1 else "medium" if ttl <= 5 else "long",
            }
        )

    # ì§§ì€ TTL í…ŒìŠ¤íŠ¸: 1ì´ˆ ëŒ€ê¸° í›„ ë§Œë£Œ í™•ì¸
    time.sleep(1.5)  # 1.5ì´ˆ ëŒ€ê¸°

    short_ttl_test = next((t for t in ttl_tests if t["ttl"] == 1), None)
    if short_ttl_test:
        expired_get = cache_manager.get(short_ttl_test["key"])
        # Memory cacheëŠ” ì¦‰ì‹œ ë§Œë£Œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ Redisê°€ ì—†ëŠ” ê²½ìš° ê´€ëŒ€í•˜ê²Œ ê²€ì¦
        ttl_results[0]["expired_get_result"] = expired_get
        ttl_results[0]["properly_expired"] = expired_get is None

    # TTL ì„¤ì • ê²€ì¦
    for result in ttl_results:
        test_framework.assert_ok(result["set_success"], f"TTL cache set should succeed")
        test_framework.assert_ok(
            result["immediate_get_success"],
            f"Immediate get should work before expiration",
        )

    assert True  # Test passed


if __name__ == "__main__":
    """
    ìºì‹œ ê³„ì¸µ ì¼ê´€ì„± í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    """

    print("ğŸ’¾ Cache Layer Consistency Integration Tests")
    print("=" * 50)

    # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = test_framework.run_all_tests()

    # ì¶”ê°€ ìƒì„¸ ë³´ê³ ì„œ
    print("\nğŸ“‹ Cache System Analysis:")
    print(f"ğŸ”„ Total cache operations logged: {len(cache_tester.cache_operations)}")
    print(f"ğŸ“Š Mock Redis operations: {cache_tester.mock_redis.operation_count}")
    print(f"ğŸ”— Redis connection status: {'Active' if cache_tester.mock_redis.connection_active else 'Failed'}")

    # ìºì‹œ ì‘ì—… ìœ í˜•ë³„ ë¶„ì„
    operation_types = {}
    for op in cache_tester.cache_operations:
        op_type = op["operation"]
        operation_types[op_type] = operation_types.get(op_type, 0) + 1

    if operation_types:
        print(f"ğŸ¯ Operation types tested: {', '.join(f'{k}({v})' for k, v in operation_types.items())}")

    # ê²°ê³¼ì— ë”°ë¥¸ ì¢…ë£Œ ì½”ë“œ
    if results["failed"] == 0:
        print(f"\nâœ… All {results['total']} Cache integration tests PASSED!")
        print("ğŸ’¾ Cache layer consistency is working correctly")
        sys.exit(0)
    else:
        print(f"\nâŒ {results['failed']}/{results['total']} Cache integration tests FAILED")
        print("ğŸ”§ Cache integration needs attention")
        sys.exit(1)
